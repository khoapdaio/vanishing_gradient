{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## **0. Import libraries**\n",
   "id": "a1c20b5e9753371e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "\n",
    "import torch\n",
    "import random\n",
    "from torch import nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "import torchvision\n",
    "from torchvision.datasets import FashionMNIST\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision.transforms as transforms\n",
    "import numpy as np\n",
    "\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "def set_seed(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "SEED = 42\n",
    "set_seed(SEED)"
   ],
   "id": "70a15b1fd5b71c6c"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## **1. Prepare dataset**\n",
   "id": "4ade5e58bef1597b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "batch_size = 512\n",
    "\n",
    "train_dataset = FashionMNIST('./data',\n",
    "                             train=True,\n",
    "                             download=True,\n",
    "                             transform=transforms.ToTensor())\n",
    "test_dataset = FashionMNIST('./data',\n",
    "                            train=False,\n",
    "                            download=True,\n",
    "                            transform=transforms.ToTensor())\n",
    "\n",
    "train_ratio = 0.9\n",
    "train_size = int(len(train_dataset) * train_ratio)\n",
    "val_size = len(train_dataset) - train_size\n",
    "\n",
    "train_subset, val_subset = random_split(train_dataset, [train_size, val_size])\n",
    "\n",
    "train_loader = DataLoader(train_subset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_subset, batch_size=batch_size, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "print(f\"Train size: {len(train_subset)}\")\n",
    "print(f\"Validation size: {len(val_subset)}\")\n",
    "print(f\"Test size: {len(test_dataset)}\")"
   ],
   "id": "e689bf685853ddb9"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## **2. Build MLP network**\n",
   "id": "e74988a2c695f6b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "class MLP_1layer(nn.Module):\n",
    "    def __init__(self, input_dims, output_dims):\n",
    "        super(MLP_1layer, self).__init__()\n",
    "        self.layer1 = nn.Linear(input_dims, output_dims)\n",
    "\n",
    "        for module in self.modules():\n",
    "            if isinstance(module, nn.Linear):\n",
    "                nn.init.normal_(module.weight, mean=0.0, std=0.05)\n",
    "                nn.init.constant_(module.bias, 0.0)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = nn.Flatten()(x)\n",
    "        x = self.layer1(x)\n",
    "        x = nn.Sigmoid()(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class MLP_2layers(nn.Module):\n",
    "    def __init__(self, input_dims, output_dims):\n",
    "        super(MLP_2layers, self).__init__()\n",
    "        self.layer1 = nn.Linear(input_dims, output_dims)\n",
    "        self.layer2 = nn.Linear(output_dims, output_dims)\n",
    "\n",
    "        for module in self.modules():\n",
    "            if isinstance(module, nn.Linear):\n",
    "                nn.init.normal_(module.weight, mean=0.0, std=0.05)\n",
    "                nn.init.constant_(module.bias, 0.0)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = nn.Flatten()(x)\n",
    "        x = self.layer1(x)\n",
    "        x = nn.Sigmoid()(x)\n",
    "        x = self.layer2(x)\n",
    "        x = nn.Sigmoid()(x)\n",
    "        return x\n",
    "\n",
    "first = MLP_2layers(input_dims=784, output_dims=128)\n",
    "second = MLP_2layers(input_dims=128, output_dims=128)\n",
    "third = MLP_2layers(input_dims=128, output_dims=128)\n",
    "fourth = MLP_1layer(input_dims=128, output_dims=128)\n",
    "\n",
    "lr = 1e-2\n",
    "criterion = nn.CrossEntropyLoss()"
   ],
   "id": "ea81da300be9b171"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## **3. Training 1**\n",
   "id": "e3be9c7df8470ab2"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "model = nn.Sequential(\n",
    "    first,\n",
    "    nn.Linear(128, 10)\n",
    ").to(device)\n",
    "\n",
    "optimizer = optim.SGD(model.parameters(), lr=lr)\n",
    "\n",
    "epochs = 100\n",
    "train_loss_lst = []\n",
    "train_acc_lst = []\n",
    "val_loss_lst = []\n",
    "val_acc_lst = []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    train_loss = 0.0\n",
    "    train_acc = 0.0\n",
    "    count = 0\n",
    "\n",
    "    model.train()\n",
    "    for X_train, y_train in train_loader:\n",
    "        X_train, y_train = X_train.to(device), y_train.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(X_train)\n",
    "        loss = criterion(outputs, y_train)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item()\n",
    "        train_acc += (torch.argmax(outputs, 1) == y_train).sum().item()\n",
    "        count += len(y_train)\n",
    "\n",
    "    train_loss /= len(train_loader)\n",
    "    train_loss_lst.append(train_loss)\n",
    "    train_acc /= count\n",
    "    train_acc_lst.append(train_acc)\n",
    "\n",
    "    val_loss = 0.0\n",
    "    val_acc = 0.0\n",
    "    count = 0\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for X_val, y_val in val_loader:\n",
    "            X_val, y_val = X_val.to(device), y_val.to(device)\n",
    "            outputs = model(X_val)\n",
    "            loss = criterion(outputs, y_val)\n",
    "            val_loss += loss.item()\n",
    "            val_acc += (torch.argmax(outputs, 1) == y_val).sum().item()\n",
    "            count += len(y_val)\n",
    "\n",
    "    val_loss /= len(test_loader)\n",
    "    val_loss_lst.append(val_loss)\n",
    "    val_acc /= count\n",
    "    val_acc_lst.append(val_acc)\n",
    "\n",
    "    print(f\"EPOCH {epoch+1}/{epochs}, Train_Loss: {train_loss:.4f}, Train_Acc: {train_acc:.4f}, Validation Loss: {val_loss:.4f}, Val_Acc: {val_acc:.4f}\")\n",
    "\n",
    "fig, ax = plt.subplots(2, 2, figsize=(12, 10))\n",
    "ax[0, 0].plot(train_loss_lst, color='green')\n",
    "ax[0, 0].set(xlabel='Epoch', ylabel='Loss')\n",
    "ax[0, 0].set_title('Training Loss')\n",
    "\n",
    "ax[0, 1].plot(val_loss_lst, color='orange')\n",
    "ax[0, 1].set(xlabel='Epoch', ylabel='Loss')\n",
    "ax[0, 1].set_title('Validation Loss')\n",
    "\n",
    "ax[1, 0].plot(train_acc_lst, color='green')\n",
    "ax[1, 0].set(xlabel='Epoch', ylabel='Accuracy')\n",
    "ax[1, 0].set_title('Training Accuracy')\n",
    "\n",
    "ax[1, 1].plot(val_acc_lst, color='orange')\n",
    "ax[1, 1].set(xlabel='Epoch', ylabel='Accuracy')\n",
    "ax[1, 1].set_title('Validation Accuracy')\n",
    "\n",
    "plt.show()\n"
   ],
   "id": "1912ad2b2de4b506"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## **4. Training 2**",
   "id": "e7c81c00f50eb57"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "\n",
    "\n",
    "for param in first.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "model = nn.Sequential(\n",
    "    first,\n",
    "    second,\n",
    "    nn.Linear(128, 10)\n",
    ").to(device)\n",
    "\n",
    "optimizer = optim.SGD(model.parameters(), lr=lr)\n",
    "\n",
    "epochs = 100\n",
    "train_loss_lst = []\n",
    "train_acc_lst = []\n",
    "val_loss_lst = []\n",
    "val_acc_lst = []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    train_loss = 0.0\n",
    "    train_acc = 0.0\n",
    "    count = 0\n",
    "\n",
    "    model.train()\n",
    "    for X_train, y_train in train_loader:\n",
    "        X_train, y_train = X_train.to(device), y_train.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(X_train)\n",
    "        loss = criterion(outputs, y_train)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item()\n",
    "        train_acc += (torch.argmax(outputs, 1) == y_train).sum().item()\n",
    "        count += len(y_train)\n",
    "\n",
    "    train_loss /= len(train_loader)\n",
    "    train_loss_lst.append(train_loss)\n",
    "    train_acc /= count\n",
    "    train_acc_lst.append(train_acc)\n",
    "\n",
    "    val_loss = 0.0\n",
    "    val_acc = 0.0\n",
    "    count = 0\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for X_val, y_val in val_loader:\n",
    "            X_val, y_val = X_val.to(device), y_val.to(device)\n",
    "            outputs = model(X_val)\n",
    "            loss = criterion(outputs, y_val)\n",
    "            val_loss += loss.item()\n",
    "            val_acc += (torch.argmax(outputs, 1) == y_val).sum().item()\n",
    "            count += len(y_val)\n",
    "\n",
    "    val_loss /= len(test_loader)\n",
    "    val_loss_lst.append(val_loss)\n",
    "    val_acc /= count\n",
    "    val_acc_lst.append(val_acc)\n",
    "\n",
    "    print(f\"EPOCH {epoch+1}/{epochs}, Train_Loss: {train_loss:.4f}, Train_Acc: {train_acc:.4f}, Validation Loss: {val_loss:.4f}, Val_Acc: {val_acc:.4f}\")\n",
    "\n",
    "fig, ax = plt.subplots(2, 2, figsize=(12, 10))\n",
    "ax[0, 0].plot(train_loss_lst, color='green')\n",
    "ax[0, 0].set(xlabel='Epoch', ylabel='Loss')\n",
    "ax[0, 0].set_title('Training Loss')\n",
    "\n",
    "ax[0, 1].plot(val_loss_lst, color='orange')\n",
    "ax[0, 1].set(xlabel='Epoch', ylabel='Loss')\n",
    "ax[0, 1].set_title('Validation Loss')\n",
    "\n",
    "ax[1, 0].plot(train_acc_lst, color='green')\n",
    "ax[1, 0].set(xlabel='Epoch', ylabel='Accuracy')\n",
    "ax[1, 0].set_title('Training Accuracy')\n",
    "\n",
    "ax[1, 1].plot(val_acc_lst, color='orange')\n",
    "ax[1, 1].set(xlabel='Epoch', ylabel='Accuracy')\n",
    "ax[1, 1].set_title('Validation Accuracy')\n",
    "\n",
    "plt.show()\n"
   ],
   "id": "6564f5e3c5d6f950"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## **5. Training 3**\n",
   "id": "6c33264b610e7529"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "\n",
    "\n",
    "for param in first.parameters():\n",
    "    param.requires_grad = False\n",
    "for param in second.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "model = nn.Sequential(\n",
    "    first,\n",
    "    second,\n",
    "    third,\n",
    "    nn.Linear(128, 10)\n",
    ").to(device)\n",
    "\n",
    "optimizer = optim.SGD(model.parameters(), lr=lr)\n",
    "\n",
    "epochs = 100\n",
    "train_loss_lst = []\n",
    "train_acc_lst = []\n",
    "val_loss_lst = []\n",
    "val_acc_lst = []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    train_loss = 0.0\n",
    "    train_acc = 0.0\n",
    "    count = 0\n",
    "\n",
    "    model.train()\n",
    "    for X_train, y_train in train_loader:\n",
    "        X_train, y_train = X_train.to(device), y_train.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(X_train)\n",
    "        loss = criterion(outputs, y_train)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item()\n",
    "        train_acc += (torch.argmax(outputs, 1) == y_train).sum().item()\n",
    "        count += len(y_train)\n",
    "\n",
    "    train_loss /= len(train_loader)\n",
    "    train_loss_lst.append(train_loss)\n",
    "    train_acc /= count\n",
    "    train_acc_lst.append(train_acc)\n",
    "\n",
    "    val_loss = 0.0\n",
    "    val_acc = 0.0\n",
    "    count = 0\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for X_val, y_val in val_loader:\n",
    "            X_val, y_val = X_val.to(device), y_val.to(device)\n",
    "            outputs = model(X_val)\n",
    "            loss = criterion(outputs, y_val)\n",
    "            val_loss += loss.item()\n",
    "            val_acc += (torch.argmax(outputs, 1) == y_val).sum().item()\n",
    "            count += len(y_val)\n",
    "\n",
    "    val_loss /= len(test_loader)\n",
    "    val_loss_lst.append(val_loss)\n",
    "    val_acc /= count\n",
    "    val_acc_lst.append(val_acc)\n",
    "\n",
    "    print(f\"EPOCH {epoch+1}/{epochs}, Train_Loss: {train_loss:.4f}, Train_Acc: {train_acc:.4f}, Validation Loss: {val_loss:.4f}, Val_Acc: {val_acc:.4f}\")\n",
    "\n",
    "fig, ax = plt.subplots(2, 2, figsize=(12, 10))\n",
    "ax[0, 0].plot(train_loss_lst, color='green')\n",
    "ax[0, 0].set(xlabel='Epoch', ylabel='Loss')\n",
    "ax[0, 0].set_title('Training Loss')\n",
    "\n",
    "ax[0, 1].plot(val_loss_lst, color='orange')\n",
    "ax[0, 1].set(xlabel='Epoch', ylabel='Loss')\n",
    "ax[0, 1].set_title('Validation Loss')\n",
    "\n",
    "ax[1, 0].plot(train_acc_lst, color='green')\n",
    "ax[1, 0].set(xlabel='Epoch', ylabel='Accuracy')\n",
    "ax[1, 0].set_title('Training Accuracy')\n",
    "\n",
    "ax[1, 1].plot(val_acc_lst, color='orange')\n",
    "ax[1, 1].set(xlabel='Epoch', ylabel='Accuracy')\n",
    "ax[1, 1].set_title('Validation Accuracy')\n",
    "\n",
    "plt.show()"
   ],
   "id": "c2d5c80a7a33534"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## **6. Training 4**\n",
   "id": "d1f7721052a3d60e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "\n",
    "\n",
    "for param in first.parameters():\n",
    "    param.requires_grad = True\n",
    "for param in second.parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "model = nn.Sequential(\n",
    "    first,\n",
    "    second,\n",
    "    third,\n",
    "    nn.Linear(128, 10)\n",
    ").to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=lr)\n",
    "\n",
    "epochs = 100\n",
    "train_loss_lst = []\n",
    "train_acc_lst = []\n",
    "val_loss_lst = []\n",
    "val_acc_lst = []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    train_loss = 0.0\n",
    "    train_acc = 0.0\n",
    "    count = 0\n",
    "\n",
    "    model.train()\n",
    "    for X_train, y_train in train_loader:\n",
    "        X_train, y_train = X_train.to(device), y_train.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(X_train)\n",
    "        loss = criterion(outputs, y_train)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item()\n",
    "        train_acc += (torch.argmax(outputs, 1) == y_train).sum().item()\n",
    "        count += len(y_train)\n",
    "\n",
    "    train_loss /= len(train_loader)\n",
    "    train_loss_lst.append(train_loss)\n",
    "    train_acc /= count\n",
    "    train_acc_lst.append(train_acc)\n",
    "\n",
    "    val_loss = 0.0\n",
    "    val_acc = 0.0\n",
    "    count = 0\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for X_val, y_val in val_loader:\n",
    "            X_val, y_val = X_val.to(device), y_val.to(device)\n",
    "            outputs = model(X_val)\n",
    "            loss = criterion(outputs, y_val)\n",
    "            val_loss += loss.item()\n",
    "            val_acc += (torch.argmax(outputs, 1) == y_val).sum().item()\n",
    "            count += len(y_val)\n",
    "\n",
    "    val_loss /= len(test_loader)\n",
    "    val_loss_lst.append(val_loss)\n",
    "    val_acc /= count\n",
    "    val_acc_lst.append(val_acc)\n",
    "\n",
    "    print(f\"EPOCH {epoch+1}/{epochs}, Train_Loss: {train_loss:.4f}, Train_Acc: {train_acc:.4f}, Validation Loss: {val_loss:.4f}, Val_Acc: {val_acc:.4f}\")\n",
    "\n",
    "fig, ax = plt.subplots(2, 2, figsize=(12, 10))\n",
    "ax[0, 0].plot(train_loss_lst, color='green')\n",
    "ax[0, 0].set(xlabel='Epoch', ylabel='Loss')\n",
    "ax[0, 0].set_title('Training Loss')\n",
    "\n",
    "ax[0, 1].plot(val_loss_lst, color='orange')\n",
    "ax[0, 1].set(xlabel='Epoch', ylabel='Loss')\n",
    "ax[0, 1].set_title('Validation Loss')\n",
    "\n",
    "ax[1, 0].plot(train_acc_lst, color='green')\n",
    "ax[1, 0].set(xlabel='Epoch', ylabel='Accuracy')\n",
    "ax[1, 0].set_title('Training Accuracy')\n",
    "\n",
    "ax[1, 1].plot(val_acc_lst, color='orange')\n",
    "ax[1, 1].set(xlabel='Epoch', ylabel='Accuracy')\n",
    "ax[1, 1].set_title('Validation Accuracy')\n",
    "\n",
    "plt.show()"
   ],
   "id": "1639d1f998019ea4"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## **7. Training 4**\n",
   "id": "33e80fa5420e0fe1"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "\n",
    "\n",
    "for param in first.parameters():\n",
    "    param.requires_grad = False\n",
    "for param in second.parameters():\n",
    "    param.requires_grad = False\n",
    "for param in third.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "model = nn.Sequential(\n",
    "    first,\n",
    "    second,\n",
    "    third,\n",
    "    fourth,\n",
    "    nn.Linear(128, 10)\n",
    ").to(device)\n",
    "\n",
    "optimizer = optim.SGD(model.parameters(), lr=lr)\n",
    "\n",
    "epochs = 100\n",
    "train_loss_lst = []\n",
    "train_acc_lst = []\n",
    "val_loss_lst = []\n",
    "val_acc_lst = []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    train_loss = 0.0\n",
    "    train_acc = 0.0\n",
    "    count = 0\n",
    "\n",
    "    model.train()\n",
    "    for X_train, y_train in train_loader:\n",
    "        X_train, y_train = X_train.to(device), y_train.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(X_train)\n",
    "        loss = criterion(outputs, y_train)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item()\n",
    "        train_acc += (torch.argmax(outputs, 1) == y_train).sum().item()\n",
    "        count += len(y_train)\n",
    "\n",
    "    train_loss /= len(train_loader)\n",
    "    train_loss_lst.append(train_loss)\n",
    "    train_acc /= count\n",
    "    train_acc_lst.append(train_acc)\n",
    "\n",
    "    val_loss = 0.0\n",
    "    val_acc = 0.0\n",
    "    count = 0\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for X_val, y_val in val_loader:\n",
    "            X_val, y_val = X_val.to(device), y_val.to(device)\n",
    "            outputs = model(X_val)\n",
    "            loss = criterion(outputs, y_val)\n",
    "            val_loss += loss.item()\n",
    "            val_acc += (torch.argmax(outputs, 1) == y_val).sum().item()\n",
    "            count += len(y_val)\n",
    "\n",
    "    val_loss /= len(test_loader)\n",
    "    val_loss_lst.append(val_loss)\n",
    "    val_acc /= count\n",
    "    val_acc_lst.append(val_acc)\n",
    "\n",
    "    print(f\"EPOCH {epoch+1}/{epochs}, Train_Loss: {train_loss:.4f}, Train_Acc: {train_acc:.4f}, Validation Loss: {val_loss:.4f}, Val_Acc: {val_acc:.4f}\")\n",
    "\n",
    "fig, ax = plt.subplots(2, 2, figsize=(12, 10))\n",
    "ax[0, 0].plot(train_loss_lst, color='green')\n",
    "ax[0, 0].set(xlabel='Epoch', ylabel='Loss')\n",
    "ax[0, 0].set_title('Training Loss')\n",
    "\n",
    "ax[0, 1].plot(val_loss_lst, color='orange')\n",
    "ax[0, 1].set(xlabel='Epoch', ylabel='Loss')\n",
    "ax[0, 1].set_title('Validation Loss')\n",
    "\n",
    "ax[1, 0].plot(train_acc_lst, color='green')\n",
    "ax[1, 0].set(xlabel='Epoch', ylabel='Accuracy')\n",
    "ax[1, 0].set_title('Training Accuracy')\n",
    "\n",
    "ax[1, 1].plot(val_acc_lst, color='orange')\n",
    "ax[1, 1].set(xlabel='Epoch', ylabel='Accuracy')\n",
    "ax[1, 1].set_title('Validation Accuracy')\n",
    "\n",
    "plt.show()"
   ],
   "id": "ca1d27d02a2e234e"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## **8. Training 6**\n",
   "id": "2bb896bedc19d13e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "\n",
    "\n",
    "for param in first.parameters():\n",
    "    param.requires_grad = True\n",
    "for param in second.parameters():\n",
    "    param.requires_grad = True\n",
    "for param in third.parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "model = nn.Sequential(\n",
    "    first,\n",
    "    second,\n",
    "    third,\n",
    "    fourth,\n",
    "    nn.Linear(128, 10)\n",
    ").to(device)\n",
    "\n",
    "optimizer = optim.SGD(model.parameters(), lr=lr)\n",
    "\n",
    "epochs = 100\n",
    "train_loss_lst = []\n",
    "train_acc_lst = []\n",
    "val_loss_lst = []\n",
    "val_acc_lst = []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    train_loss = 0.0\n",
    "    train_acc = 0.0\n",
    "    count = 0\n",
    "\n",
    "    model.train()\n",
    "    for X_train, y_train in train_loader:\n",
    "        X_train, y_train = X_train.to(device), y_train.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(X_train)\n",
    "        loss = criterion(outputs, y_train)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item()\n",
    "        train_acc += (torch.argmax(outputs, 1) == y_train).sum().item()\n",
    "        count += len(y_train)\n",
    "\n",
    "    train_loss /= len(train_loader)\n",
    "    train_loss_lst.append(train_loss)\n",
    "    train_acc /= count\n",
    "    train_acc_lst.append(train_acc)\n",
    "\n",
    "    val_loss = 0.0\n",
    "    val_acc = 0.0\n",
    "    count = 0\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for X_val, y_val in val_loader:\n",
    "            X_val, y_val = X_val.to(device), y_val.to(device)\n",
    "            outputs = model(X_val)\n",
    "            loss = criterion(outputs, y_val)\n",
    "            val_loss += loss.item()\n",
    "            val_acc += (torch.argmax(outputs, 1) == y_val).sum().item()\n",
    "            count += len(y_val)\n",
    "\n",
    "    val_loss /= len(test_loader)\n",
    "    val_loss_lst.append(val_loss)\n",
    "    val_acc /= count\n",
    "    val_acc_lst.append(val_acc)\n",
    "\n",
    "    print(f\"EPOCH {epoch+1}/{epochs}, Train_Loss: {train_loss:.4f}, Train_Acc: {train_acc:.4f}, Validation Loss: {val_loss:.4f}, Val_Acc: {val_acc:.4f}\")\n",
    "\n",
    "fig, ax = plt.subplots(2, 2, figsize=(12, 10))\n",
    "ax[0, 0].plot(train_loss_lst, color='green')\n",
    "ax[0, 0].set(xlabel='Epoch', ylabel='Loss')\n",
    "ax[0, 0].set_title('Training Loss')\n",
    "\n",
    "ax[0, 1].plot(val_loss_lst, color='orange')\n",
    "ax[0, 1].set(xlabel='Epoch', ylabel='Loss')\n",
    "ax[0, 1].set_title('Validation Loss')\n",
    "\n",
    "ax[1, 0].plot(train_acc_lst, color='green')\n",
    "ax[1, 0].set(xlabel='Epoch', ylabel='Accuracy')\n",
    "ax[1, 0].set_title('Training Accuracy')\n",
    "\n",
    "ax[1, 1].plot(val_acc_lst, color='orange')\n",
    "ax[1, 1].set(xlabel='Epoch', ylabel='Accuracy')\n",
    "ax[1, 1].set_title('Validation Accuracy')\n",
    "\n",
    "plt.show()\n"
   ],
   "id": "f989007fd31a1cea"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## **9. Evaluation**\n",
   "id": "868ea0fa091a77be"
  },
  {
   "metadata": {
    "collapsed": true
   },
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "val_target = []\n",
    "val_predict = []\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for X_val, y_val in val_loader:\n",
    "        X_val = X_val.to(device)\n",
    "        y_val = y_val.to(device)\n",
    "        outputs = model(X_val)\n",
    "\n",
    "        val_predict.append(outputs.cpu())\n",
    "        val_target.append(y_val.cpu())\n",
    "\n",
    "    val_predict = torch.cat(val_predict)\n",
    "    val_target = torch.cat(val_target)\n",
    "    val_acc = (torch.argmax(val_predict, 1) == val_target).sum().item() / len(val_target)\n",
    "\n",
    "    print('Evaluation on val set:')\n",
    "    print(f'Accuracy: {val_acc}')\n",
    "\n",
    "test_target = []\n",
    "test_predict = []\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for X_test, y_test in test_loader:\n",
    "        X_test = X_test.to(device)\n",
    "        y_test = y_test.to(device)\n",
    "        outputs = model(X_test)\n",
    "\n",
    "        test_predict.append(outputs.cpu())\n",
    "        test_target.append(y_test.cpu())\n",
    "\n",
    "    test_predict = torch.cat(test_predict)\n",
    "    test_target = torch.cat(test_target)\n",
    "    test_acc = (torch.argmax(test_predict, 1) == test_target).sum().item() / len(test_target)\n",
    "\n",
    "    print('Evaluation on test set:')\n",
    "    print(f'Accuracy: {test_acc}')"
   ],
   "id": "initial_id"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
